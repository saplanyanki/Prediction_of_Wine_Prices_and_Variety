# -*- coding: utf-8 -*-
"""Yanki_Project_Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NXN1RzQfpZARhiiL0Em6T69o46m4E4wX
"""

#Libraries
import pandas as pd
import numpy as np
import scipy
from scipy.stats import mode
from numpy import mean
from numpy import std
from sklearn import metrics
import math
import plotly.express as px
from sklearn.pipeline import make_pipeline
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, GridSearchCV 
from sklearn.linear_model import Lasso
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.model_selection import RepeatedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA

from google.colab import drive
drive.mount('/content/gdrive')

#Read in the Data
data = pd.read_csv("/content/gdrive/My Drive/DS320_Project/Data/winemag-data_first150k.csv")
data.head(5)

"""# Data Cleaning

Items to address

*   fillna
*   description
"""

# Remove 'Unnamed: 0' and description
# data.drop('Unnamed: 0', axis=1, inplace=True)
# data.drop('description', axis=1, inplace=True)

# Remove rows with missing 'country' and 'province'
# data = data.dropna(subset=['country']) # This addresses both missing values

# # Consider dropping 'designation', 'region_1', and 'region_2'
# data.drop('designation', axis=1, inplace=True)
# #data.drop('region_1', axis=1, inplace=True)
# data.drop('region_2', axis=1, inplace=True)

"""Choose One:



*   Overall Mean
*   Variety Mean


"""

# Replace with overall mean
# data['price'].fillna(data['price'].mean(), inplace=True)

# # Replace with variety mean
# data['price'].fillna(data.groupby(['variety'])['price'].transform('mean'), inplace=True) # Leaves some left over cases with na
# data = data.dropna(subset=['price']) # Removes left over cases

# #data['region_1'].fillna(data.groupby(['province'])['region_1'].transform('mode'), inplace=True)
# #data = data.dropna(subset=['region_1'])

# # function to fill NAs with mode for region_1, if there is more than 1 mode or no mode, then return x
# def get_mode_or_x(series):
#     mode = series.mode()
#     if mode.size == 1:
#         return mode[0]
#     return "x"

# data.loc[:, "region_1"] = data['region_1'].fillna(data.groupby("province")["region_1"].transform(get_mode_or_x))

# #only selecting rows that have values and not x
# data = data[data.region_1 != 'x']

data.isnull().sum()

"""

```
# This is formatted as code
```

# Exploratory Data Analysis"""

provinceCount =  data.groupby(['province'])
provinceCount = provinceCount['province'].count()
provinceCount = provinceCount.nlargest(10, 'first')
provinceCount = px.bar(provinceCount, x = 'province', title = 'Top 10 Wine Producing Provinces', width = 800, height = 800)
provinceCount.update_layout(yaxis_title = "province", xaxis_title = "count")
provinceCount.show()

priceDist = data[data['price'] < 250]
priceDistFig = px.histogram(priceDist, 'price', title = 'Distribution of Wine Price', width = 800, height = 800, nbins = 30)
priceDistFig.show()

pointsDistFig = px.histogram(data, 'points', title = 'Distribution of Wine Points', width = 800, height = 800, nbins = 30)
pointsDistFig.show()

countryCount =  data.groupby(['variety']).size().reset_index(name = "count").nlargest(10, 'count')
countryFig = px.pie(countryCount, 'variety', 'count', color = 'variety', title = 'Top 10 Wine Varieties', width = 800, height = 800)
countryFig.show()

"""# Machine Learning"""

##JUST RUN THIS BAD BOY TO AVOID RE RUNNING EVERYTHING AGAIN
data = pd.read_csv("/content/gdrive/My Drive/DS320_Project/Data/winemag-data_first150k.csv")
data.head(5)

def get_mode_or_x(series):
  mode = series.mode()
  if mode.size == 1:
      return mode[0]
  return "x"

def domestic(row):
    if row['country'] == 'US':
        val = 1
    else:
        val = 0
    return val

def expensive(row):
    means = data.price.mean()
    if row['price'] > means:
        val = 1
    else:
        val = 0
    return val
pd.options.mode.chained_assignment = None  # default='warn'

def titan(data):
  # Remove 'Unnamed: 0' and description
  new_data = data
  new_data.drop('Unnamed: 0', axis=1, inplace=True)
  new_data.drop('description', axis=1, inplace=True)
  new_data = new_data.dropna(subset=['country'])
  new_data.drop('designation', axis=1, inplace=True)
  #data.drop('region_1', axis=1, inplace=True)
  new_data.drop('region_2', axis=1, inplace=True)

  # Replace with variety mean
  new_data['price'].fillna(new_data.groupby(['variety'])['price'].transform('mean'), inplace=True) # Leaves some left over cases with na
  print('======VARIETY MEAN NA======')
  new_data = new_data.dropna(subset=['price']) # Removes left over cases
  print('======FINISHED DROPPING======')
  new_data.loc[:, "region_1"] = new_data['region_1'].fillna(data.groupby("province")["region_1"].transform(get_mode_or_x))
  new_data = new_data[data.region_1 != 'x']
  print('======MODE NA FOR REGION_1======')
  new_data['Domestic'] = new_data.apply(domestic, axis=1)
  #new_data.drop('country', axis=1, inplace=True)
  new_data['Expensive'] = new_data.apply(expensive, axis=1)
  for col in ['variety', 'province', 'region_1', 'winery']:
    new_data[col] = new_data[col].str.lower()
  print('======STRING LOW FOR ALL======')

  ##Reduce the lower counts from columns to avoid high dimensionality
  counts = new_data['variety'].value_counts()
  var_mean = new_data['variety'].value_counts().mean()
  counts1 = new_data['winery'].value_counts()
  winery_mean = new_data['winery'].value_counts().mean()
  new_data = new_data[~new_data['variety'].isin(counts[counts < var_mean].index)]
  new_data = new_data[~new_data['winery'].isin(counts1[counts1 < winery_mean].index)]

  print(len(new_data))
  print('======CLASS BALANCE FOR DOMESTIC======')
  #print('{}'.format(round(new_data['Domestic'].value_counts()/len(new_data)*100,3)))
  #print('{}'.format(round(new_data['variety'].value_counts()/len(new_data)*100,3)))
  #print('{}'.format(round(new_data['winery'].value_counts()/len(new_data)*100,3)))
  print('======CLASS BALANCE FOR VARIETY======')
  print('======THANKS FOR USING TITAN======')
  return new_data


newdata = titan(data)

counts1 = newdata['winery'].value_counts()
winery_mean = newdata['winery'].value_counts().mean()
newdata = newdata[~newdata['winery'].isin(counts1[counts1 < winery_mean].index)]
newdata.winery.value_counts()

a = newdata
b = pd.DataFrame(a.groupby('variety').count()['Expensive'] / len(a)).reset_index()
b = b.rename(columns={'Expensive': 'Posterior_variety_expensive'})
newdata1 = pd.merge(a, b, how ='left', on ='variety')
newdata1

"""**Classification**"""

#FOR CLASSIFICATION
target = newdata1['variety']
newdata1.drop('variety', axis=1, inplace=True)

top_winery = list(newdata1.winery.value_counts().head(100).index)
def top_winery_or_not(row):
  if row['winery'] in top_winery:
        val = 1
  else:
      val = 0
  return val

newdata1['top_winery_or_not'] = newdata1.apply(top_winery_or_not, axis=1)

def province_reducer(row):
  if row['Domestic'] == 1:
        val = 1
  else:
      val = 0
  return val

newdata1['usa_province_or_not'] = newdata1.apply(province_reducer, axis=1)

newdata1['region_1_last_word'] = newdata1['region_1'].apply(lambda x: x.split(' ')[-1])
top_region1 = list(newdata1.region_1_last_word.value_counts().head(50).index)
def top_region_1_or_not(row):
  if row['region_1'] in top_region1:
        val = 1
  else:
      val = 0
  return val

newdata1['top_region_1_or_not'] = newdata1.apply(top_region_1_or_not, axis=1)

newdata1.drop('country', axis=1, inplace=True)
newdata1.drop('winery', axis=1, inplace=True)
newdata1.drop('province', axis=1, inplace=True)
newdata1.drop('region_1', axis=1, inplace=True)
newdata1.drop('region_1_last_word', axis=1, inplace=True)

newdata1.top_region_1_or_not.value_counts()

newdata1

features = pd.get_dummies(newdata1)
X = features
y = target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state = 77)

X_train

# Standardizing
pipeline = Pipeline([
    ('std_scalar', StandardScaler())
])

X_train = pipeline.transform(X_train)
X_test = pipeline.transform(X_test)

X_train = StandardScaler().fit_transform(X_train)
X_test = StandardScaler().fit_transform(X_test)
X_train = pd.DataFrame(X_train)
X_test = pd.DataFrame(X_test)

pca = PCA(n_components=0.95)
tr_comp = pca.fit_transform(X_train)
ts_comp = pca.transform(X_test)

def print_evaluate(true, predicted):  
    f1 = metrics.f1_score(true, predicted, average='macro')
    acc = metrics.accuracy_score(true, predicted)
    prec = metrics.precision_score(true, predicted, average='macro')
    recall = metrics.recall_score(true, predicted, average='macro')
    print('F1:', f1)
    print('Accuracy:', acc)
    print('Precission:', prec)
    print('Recall', recall)
    print('__________________________________')
    
def evaluate(true, predicted):
    f1 = metrics.f1_score(true, predicted, average='macro')
    acc = metrics.accuracy_score(true, predicted)
    prec = metrics.precision_score(true, predicted, average='macro')
    recall = metrics.recall_score(true, predicted, average='macro')
    return f1, acc, prec, recall

#KNN
classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)

knn_test_pred = classifier.predict(X_test)
knn_train_pred = classifier.predict(X_train)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, knn_train_pred)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, knn_test_pred)


results_df = pd.DataFrame(data=[["KNN", *evaluate(y_test, knn_test_pred), 0]], columns=['Model', 'F1', 'Accuracy', 'Precision', 'Recall', 'Cross Validation'])

#RF
rf=RandomForestClassifier(n_estimators=200)

rf.fit(X_train,y_train)

rf_train_pred = rf.predict(X_train)
rf_test_pred = rf.predict(X_test)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, rf_train_pred)
print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, rf_test_pred)



results_df_2 = pd.DataFrame(data=[["Random Forest", *evaluate(y_test, rf_test_pred), 0]], 
                            columns=['Model', 'F1', 'Accuracy', 'Precision', 'Recall', 'Cross Validation'])
results_df = results_df.append(results_df_2, ignore_index=True)

#SVM
#Create a svm Classifier
support = svm.SVC(kernel='linear')
X_train = StandardScaler().fit_transform(X_train)
X_test = StandardScaler().fit_transform(X_test)
# from sklearn.preprocessing import MinMaxScaler
# scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)
# X_train = scaling.transform(X_train)
# X_test = scaling.transform(X_test)
support.fit(X_train, y_train)

svm_train_pred = support.predict(X_train)
svm_test_pred = support.predict(X_test)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, svm_test_pred)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, svm_train_pred)

results_df_2 = pd.DataFrame(data=[["SVM", *evaluate(y_test, svm_test_pred), 0]], 
                            columns=['Model', 'F1', 'Accuracy', 'Precision', 'Recall', 'Cross Validation'])
results_df = results_df.append(results_df_2, ignore_index=True)

#Naive Bayes
gnb = GaussianNB()
naive = gnb.fit(X_train, y_train)

naive_train_pred = naive.predict(X_train)
naive_test_pred = naive.predict(X_test)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, naive_test_pred)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, naive_train_pred)

results_df_2 = pd.DataFrame(data=[["Navie Bayes", *evaluate(y_test, naive_test_pred), 0]], 
                            columns=['Model', 'F1', 'Accuracy', 'Precision', 'Recall', 'Cross Validation'])
results_df = results_df.append(results_df_2, ignore_index=True)

all_models = [
    ('knn', KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)), 
    ('rf', RandomForestClassifier(n_estimators=200)),
    ('naive', GaussianNB()),
    ('svm', svm.SVC(kernel='linear'))]

classifiers = StackingClassifier(estimators = all_models, final_estimator = RandomForestClassifier())

X_train = StandardScaler().fit_transform(X_train)
X_test = StandardScaler().fit_transform(X_test)

classifiers.fit(X_train, y_train)
pred = classifiers.predict(X_test)

test_pred = classifiers.predict(X_test)
train_pred = classifiers.predict(X_train)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)
print('====================================')
print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)


results_df_2 = pd.DataFrame(data=[["Ensemble Stacking All Models", *evaluate(y_test, test_pred), 0]], 
                            columns=['Model', 'F1', 'Accuracy', 'Precision', 'Recall', 'Cross Validation'])
results_df = results_df.append(results_df_2, ignore_index=True)

df = results_df.reset_index(drop=False)
df.sort_values('Accuracy', inplace=True)
df.set_index('Model', inplace=True)
df['Accuracy'].plot(kind='barh', figsize=(12, 8), color={'green','black','red','purple','blue'})

"""**Regression**"""

from numpy import mean
from numpy import std
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from matplotlib import pyplot
from sklearn import metrics

target = newdata1['points']
newdata1.drop('points', axis=1, inplace=True)
newdata1.drop('region_1', axis=1, inplace=True)

features = pd.get_dummies(newdata1)

X = features
y = target

from sklearn.preprocessing import StandardScaler
x = StandardScaler().fit_transform(X)

from sklearn.decomposition import PCA
pca = PCA(n_components=8)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['PCA_1', 'PCA_2','PCA_3', 'PCA_4','PCA_5', 'PCA_6',
                          'PCA_7', 'PCA_8'])

finalDf_reg = pd.concat([principalDf, y], axis = 1)
finalDf_reg

featuresPCA = ['PCA_1', 'PCA_2','PCA_3', 'PCA_4','PCA_5', 'PCA_6','PCA_7', 'PCA_8']

X1_reg = finalDf_reg.loc[:, featuresPCA].values
target_reg = finalDf_reg['points']
y1_reg = target_reg

X_train, X_test, y_train, y_test = train_test_split(X1_reg, y1_reg, test_size=0.3, stratify=y, random_state = 77)

def cross_val(model):
    pred = cross_val_score(model, X1_reg, y1_reg, cv=10)
    return pred.mean()

def print_evaluate(true, predicted):  
    mae = metrics.mean_absolute_error(true, predicted)
    mse = metrics.mean_squared_error(true, predicted)
    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))
    r2_square = metrics.r2_score(true, predicted)
    print('MAE:', mae)
    print('MSE:', mse)
    print('RMSE:', rmse)
    print('R2 Square', r2_square)
    print('__________________________________')
    
def evaluate(true, predicted):
    mae = metrics.mean_absolute_error(true, predicted)
    mse = metrics.mean_squared_error(true, predicted)
    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))
    r2_square = metrics.r2_score(true, predicted)
    return mae, mse, rmse, r2_square

#SVM
from sklearn.svm import SVR
svm_reg = SVR(kernel='rbf', C=10, epsilon=0.001)
svm_reg.fit(X_train, y_train)

test_pred = svm_reg.predict(X_test)
train_pred = svm_reg.predict(X_train)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)

results_df = pd.DataFrame(data=[["SVM Regressor", *evaluate(y_test, test_pred), 0]], 
                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])

#Random Forest
from sklearn.ensemble import RandomForestRegressor

rf_reg = RandomForestRegressor(n_estimators=100)
rf_reg.fit(X_train, y_train)

test_pred = rf_reg.predict(X_test)
train_pred = rf_reg.predict(X_train)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)

results_df_2 = pd.DataFrame(data=[["Random Forest Regressor", *evaluate(y_test, test_pred), 0]], 
                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])
results_df = results_df.append(results_df_2, ignore_index=True)

#Ridge
from sklearn.linear_model import Ridge

model = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)
model.fit(X_train, y_train)
pred = model.predict(X_test)

test_pred = model.predict(X_test)
train_pred = model.predict(X_train)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)
print('====================================')
print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)

results_df_2 = pd.DataFrame(data=[["Ridge Regression", *evaluate(y_test, test_pred) , cross_val(Ridge())]], 
                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', "Cross Validation"])
results_df = results_df.append(results_df_2, ignore_index=True)

#Lasso
from sklearn.linear_model import Lasso

model = Lasso(alpha=0.1, 
              precompute=True, 
#               warm_start=True, 
              positive=True, 
              selection='random',
              random_state=42)
model.fit(X_train, y_train)

test_pred = model.predict(X_test)
train_pred = model.predict(X_train)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)
print('====================================')
print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)

results_df_2 = pd.DataFrame(data=[["Lasso Regression", *evaluate(y_test, test_pred) , cross_val(Lasso())]], 
                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', "Cross Validation"])
results_df = results_df.append(results_df_2, ignore_index=True)

#ANN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Activation, Dropout
from tensorflow.keras.optimizers import Adam

X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)

model = Sequential()

model.add(Dense(X_train.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
# model.add(Dropout(0.2))

model.add(Dense(64, activation='relu'))
# model.add(Dropout(0.2))

model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.2))

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1))

model.compile(optimizer=Adam(0.00001), loss='mse')

r = model.fit(X_train, y_train,
              validation_data=(X_test,y_test),
              batch_size=1,
              epochs=10)

pd.DataFrame({'True Values': y_test, 'Predicted Values': pred}).hvplot.scatter(x='True Values', y='Predicted Values')

pd.DataFrame(r.history)

pd.DataFrame(r.history).hvplot.line(y=['loss', 'val_loss'])

test_pred = model.predict(X_test)
train_pred = model.predict(X_train)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)

print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)

results_df_2 = pd.DataFrame(data=[["Artficial Neural Network", *evaluate(y_test, test_pred), 0]], 
                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])
results_df = results_df.append(results_df_2, ignore_index=True)

results_df

results_df.set_index('Model', inplace=True)
results_df['R2 Square'].plot(kind='barh', figsize=(12, 8))

